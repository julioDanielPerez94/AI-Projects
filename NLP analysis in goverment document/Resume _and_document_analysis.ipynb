{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f90982e",
   "metadata": {},
   "source": [
    "# Edosoft - Resumen y clasificación de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c413f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import PyPDF2\n",
    "from tika import parser\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f86a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"prueba_es.txt\", \"r\", encoding='utf8')\n",
    "lines = file.readlines()\n",
    "\n",
    "datos = {'Documentos':lines}\n",
    "df = pd.DataFrame(data = datos)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Documentos'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Primero tokenizamos los 4 primeros documentos\n",
    "# def tokenize_words(text):\n",
    "#     sin_puntuacion = text.translate(str.maketrans('', '', string.punctuation))\n",
    "#     tokenized_text=word_tokenize(sin_puntuacion)\n",
    "#     print(tokenized_text)\n",
    "#     print(type(tokenized_text))\n",
    "    \n",
    "#     return tokenized_text\n",
    "\n",
    "# # df_tokenized = df.copy()\n",
    "# df['Documentos'] = df['Documentos'].apply(lambda x: tokenize_words(x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87665b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "# #from nltk and spacy library\n",
    "# total_spanish_stopwords = list(stopwords.words(\"spanish\")) + stopword_es\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     text = [word for word in text if word not in stopword_es]\n",
    "#     return text\n",
    "\n",
    "# df['Sin_stopwords'] = df['Documentos'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Sin_stopwords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def spanish_stemmer(x):\n",
    "#     spanish_stemmer_ = SnowballStemmer(language = 'spanish')\n",
    "#     for i in range(len(x)):\n",
    "# #         print(i)\n",
    "#         for l in range(len(x[i])):\n",
    "# #             print(l)\n",
    "#             x[i][l] = spanish_stemmer_.stem(x[i][l])\n",
    "# #             print(x[i])\n",
    "#     return x\n",
    "    \n",
    "# df['words_stemmed'] = spanish_stemmer(df['Sin_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['words_stemmed'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881894c3",
   "metadata": {},
   "source": [
    "## Empezamos a hacer el resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9bbac",
   "metadata": {},
   "source": [
    "Trying with the following guide: [Click on here](https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Documentos'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(df['Documentos'][0]) # NLTK function\n",
    "total_documents = len(sentences)\n",
    "\n",
    "stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "#from nltk and spacy library\n",
    "total_spanish_stopwords = list(stopwords.words(\"spanish\")) + stopword_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47959214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d5c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    \n",
    "    stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "    #from nltk and spacy library\n",
    "    total_spanish_stopwords = list(stopwords.words(\"spanish\")) + stopword_es\n",
    "    stopWords = total_spanish_stopwords\n",
    "    ps = SnowballStemmer(language = 'spanish')\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "\n",
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "\n",
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix= _create_frequency_matrix(sentences)\n",
    "\n",
    "tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "\n",
    "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "\n",
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "\n",
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "\n",
    "sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "\n",
    "threshold = _find_average_score(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = _generate_summary(sentences, sentence_scores, 1* threshold)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Documentos'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2 = open(\"boe.txt\", \"r\", encoding='utf8')\n",
    "lines_2 = file_2.readlines()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=[lines,lines_2],columns=['Documento'])\n",
    "df['Documento'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Documento'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be526116",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boe.txt', encoding='Latin1') as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455ee7f",
   "metadata": {},
   "source": [
    "##### https://www.simplifiedpython.net/pdf-to-text-python-extract-text-from-pdf-documents-using-pypdf2-module/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9687da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObject = open(r\"prueba_es.pdf\", 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "print(\" No. Of Pages :\", pdfReader.numPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fa631",
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObject = pdfReader.getPage(0)\n",
    " \n",
    "print(pageObject.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = pdfReader.getPage(0).extractText() + pdfReader.getPage(1).extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto.replace('\\n',' ').lstrip().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texto = \" \".join(texto.replace('\\n',' ').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba91736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file\n",
    "\n",
    "from tika import parser\n",
    "\n",
    "raw = parser.from_file('prueba_es.pdf')\n",
    "print(raw['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(raw['content'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23806366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tutorialspoint.com/working-with-pdf-files-in-python\n",
    "\n",
    "# with open('BOE-A-2010-4132.pdf', 'rb') as f:\n",
    "#     pdf = PyPDF2.PdfFileReader(f)\n",
    "#     info = pdf.getDocumentInfo()\n",
    "#     number_of_pages = pdf.getNumPages()\n",
    "\n",
    "# print(\"Author: \\t\", info.author)\n",
    "# print()\n",
    "# print(\"Creator: \\t\", info.creator)\n",
    "# print()\n",
    "# print(\"Producer: \\t\",info.producer)\n",
    "# print()\n",
    "# print(\"Subject: \\t\", info.subject)\n",
    "# print()\n",
    "# print(\"title: \\t\",info.title)\n",
    "# print()\n",
    "# print(\"Number of Pages in pdf: \\t\",number_of_pages)\n",
    "\n",
    "# prueba = ''\n",
    "# for i in range(pdf.getNumPages()):\n",
    "#     prueba = prueba + pdf.getPage(i).extractText()\n",
    "#     print(len(prueba))\n",
    "    \n",
    "# pdf.getPage(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9256ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf.getPage(2).extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BOE-A-2010-4132.pdf', 'rb') as f:\n",
    "    pdf = PyPDF2.PdfFileReader(f)\n",
    "    info = pdf.getDocumentInfo()\n",
    "    number_of_pages = pdf.getNumPages()\n",
    "print(\"Author: \\t\", info.author)\n",
    "print()\n",
    "print(\"Creator: \\t\", info.creator)\n",
    "print()\n",
    "print(\"Producer: \\t\",info.producer)\n",
    "print()\n",
    "print(\"Subject: \\t\", info.subject)\n",
    "print()\n",
    "print(\"title: \\t\",info.title)\n",
    "print()\n",
    "print(\"Number of Pages in pdf: \\t\",number_of_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfFileObject = open('BOE-A-2010-4132.pdf', 'rb')\n",
    "# pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "# prueba = ''\n",
    "# for i in range(pdfReader.getNumPages()):\n",
    "#     prueba = prueba + pdfReader.getPage(i).extractText()\n",
    "#     print(len(prueba))\n",
    "# prueba = prueba.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19519305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfReader.getPage(1).extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader.getDocumentInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = 'BOE-A-2010-4132.pdf'\n",
    "\n",
    "with open(documento, 'rb') as f:\n",
    "    pdf = PyPDF2.PdfFileReader(f)\n",
    "    info = pdf.getDocumentInfo()\n",
    "    number_of_pages = pdf.getNumPages()\n",
    "\n",
    "# text = ''\n",
    "# for i in range(pdf.getNumPages()):\n",
    "#     text = text + pdf.getPage(i).extractText()\n",
    "#     print(len(prueba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b1f571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluir el documento en PDF\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def resume_pdfs(documento, alpha):\n",
    "    \n",
    "    #### First parser of PDFs files\n",
    "    # ==============================================================================\n",
    "    \n",
    "    pdfFileObject = open(documento, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "#     text = ''\n",
    "#     for i in range(pdfReader.getNumPages()):\n",
    "#         text = text + pdfReader.getPage(i).extractText()\n",
    "#     text = text.replace('\\n',' ')\n",
    "#     print(text)\n",
    "#         print(len(prueba))\n",
    "      \n",
    "    \n",
    "    #### Second parser of PDFs files\n",
    "    # ==============================================================================\n",
    "    raw = parser.from_file(documento)\n",
    "#     print(raw['content'])\n",
    "\n",
    "    text = \" \".join(raw['content'].split())\n",
    "\n",
    "    # -----------------------------------\n",
    "    \n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    total_documents = len(sentences)\n",
    "    #print(sentences)\n",
    "\n",
    "    # 2 Create the Frequency matrix of the words in each sentence.\n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    #print(freq_matrix)\n",
    "\n",
    "    '''\n",
    "    Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
    "    '''\n",
    "    # 3 Calculate TermFrequency and generate a matrix\n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    #print(tf_matrix)\n",
    "\n",
    "    # 4 creating table for documents per words\n",
    "    count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "    #print(count_doc_per_words)\n",
    "\n",
    "    '''\n",
    "    Inverse document frequency (IDF) is how unique or rare a word is.\n",
    "    '''\n",
    "    # 5 Calculate IDF and generate a matrix\n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "    #print(idf_matrix)\n",
    "\n",
    "    # 6 Calculate TF-IDF and generate a matrix\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    #print(tf_idf_matrix)\n",
    "\n",
    "    # 7 Important Algorithm: score the sentences\n",
    "    sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "    #print(sentence_scores)\n",
    "\n",
    "    # 8 Find the threshold\n",
    "    threshold = _find_average_score(sentence_scores)\n",
    "    #print(threshold)\n",
    "\n",
    "    # 9 Important Algorithm: Generate the summary (alpha between 0.5 - 1.5)\n",
    "    summary = _generate_summary(sentences, sentence_scores, alpha * threshold)\n",
    "    \n",
    "    \n",
    "    print(\"Título: \\t\",pdfReader.getDocumentInfo().title)\n",
    "    print('--------------------------------------------------------------------')\n",
    "    print(\"Número de páginas: {} \\nLongitud del documento original: {}\\nLongitud del resumen: {}\".format(pdfReader.getNumPages(), len(text), len(summary)))\n",
    "    print('--------------------------------------------------------------------')\n",
    "    print(summary)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011c7f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: \t Disposición 4132 del BOE núm. 62 de 2010\n",
      "--------------------------------------------------------------------\n",
      "Número de páginas: 10 \n",
      "Longitud del documento original: 33619\n",
      "Longitud del resumen: 8502\n",
      "--------------------------------------------------------------------\n",
      " Disposición 4132 del BOE núm. 62 de 2010 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. Objeto. 1. Los requisitos mínimos se referirán a la titulación académica del profesorado, la relación numérica alumno-profesor, las instalaciones docentes y deportivas y el número de puestos escolares. 2. Artículo 2. Denominación de los centros docentes. Artículo 3. Requisitos de instalaciones comunes a todos los centros. 1. 2. b) Reunir las condiciones de seguridad estructural, de seguridad en caso de incendio, de seguridad de utilización, de salubridad, de protección frente al ruido y de ahorro de energía que señala la legislación vigente. Asimismo, deberán cumplir los requisitos de protección laboral establecidos en la legislación vigente. c) Tener, en los espacios en los que se desarrolle la práctica docente ventilación e iluminación natural y directa desde el exterior. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. Espacios destinados a la administración. Sala de profesores adecuada al número de profesores. Espacios apropiados para las reuniones de las asociaciones de alumnos y de madres y padres de alumnos, en el caso de centros sostenidos con fondos públicos. Espacios necesarios para impartir los apoyos al alumnado con necesidades específicas de apoyo educativo. 3. En ningún caso será inferior 900 metros cuadrados. Biblioteca, con una superficie, como mínimo, de 45 metros cuadrados en los centros que impartan la educación primaria, y 75 metros cuadrados en los centros que impartan la educación secundaria obligatoria o el bachillerato. Un gimnasio con una superficie adecuada al número de puestos escolares. 4. Los requisitos de instalaciones podrán flexibilizarse de acuerdo con lo establecido en el artículo 20 y la disposición adicional tercera de este real decreto. Artículo 4. Puestos escolares. 1. 2. TÍTULO II De los centros de educación infantil Artículo 5. Condiciones generales. 1. Los centros podrán ofrecer el primer ciclo de esta etapa educativa, el segundo, o ambos. 2. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 24834 Artículo 6. Instalaciones y condiciones materiales de los centros que ofrecen el segundo ciclo de la educación infantil. 1. 2. b) Una sala polivalente de 30 metros cuadrados. Artículo 7. Relación alumnos por unidad. Artículo 8. Requisitos de titulación de los profesionales que atienden la educación infantil. 1. 2. 3. El segundo ciclo de educación infantil correrá a cargo de profesionales que posean el título de Grado en Educación infantil, o el título de Maestro con la especialidad de educación infantil. Cuando las enseñanzas impartidas lo requieran, el grupo podrá ser atendido por maestros de otras especialidades. 4. 5. 6. Los recursos humanos a que se refiere el párrafo anterior deberán disponer de la titulación o cualificación adecuada. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 24835 TÍTULO III De los centros de educación primaria Artículo 9. Condiciones generales. Artículo 10. Instalaciones y condiciones materiales de los centros. b) Un espacio por cada seis unidades para desdoblamiento de grupos y otro para actividades de apoyo y refuerzo pedagógico. c) Una sala polivalente, con una superficie adecuada al número de puestos escolares autorizados, que podrá compartimentarse con mamparas móviles. Artículo 11. Relación de alumnos por unidad. Artículo 12. Requisitos de titulación académica del profesorado que imparte educación primaria. 1. 2. Los recursos humanos a que se refiere el párrafo anterior deberán disponer de la titulación o cualificación adecuada. TÍTULO IV De los centros de educación secundaria Artículo 13. Condiciones generales. 1. 2. 3. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 4. 5. Artículo 14. Instalaciones y condiciones materiales de los centros que imparten educación secundaria obligatoria. c) Al menos un laboratorio de Ciencias Experimentales por cada 12 unidades o fracción. d) Un espacio por cada ocho unidades para desdoblamiento de grupos y otro para actividades de apoyo y refuerzo pedagógico. Artículo 15. Instalaciones y condiciones materiales de los centros que imparten bachillerato. 1. 2. Un espacio por cada cuatro unidades para desdoblamiento de grupos y otro para actividades de apoyo y refuerzo pedagógico. 3. Un aula de música cuando se imparta la vía de artes escénicas, música y danza. b) Para la modalidad de Ciencias y Tecnología: Tres laboratorios diferenciados de Física, Química y Ciencias. Un aula de dibujo. Un aula de Tecnología. Artículo 16. Relación de alumnos por unidad. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 24837 Artículo 17. Profesionales que atienden la educación secundaria obligatoria y el bachillerato. 1. 2. Artículo 18. Número mínimo de profesores de los centros que ofrecen la educación secundaria obligatoria y el bachillerato. 1. 2. Este personal deberá estar en posesión de la titulación o cualificación adecuada. Artículo 19. Requisitos de centros que ofrecen los Programas de Cualificación Profesional Inicial. 1. 2. Artículo 20. Flexibilización de los requisitos de instalaciones para los centros docentes que impartan distintas enseñanzas en el mismo edificio o recinto escolar. 1. 2. b) El gimnasio. c) El patio de recreo. d) Los despachos de dirección, los espacios destinados a la administración y la sala de profesores. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 24838 3. Asimismo cubre la exigencia del aula de educación plástica y visual para la educación secundaria obligatoria. c) El aula de música para el bachillerato de artes en la vía de artes escénicas, música y danza, cubre la exigencia del aula de música para la educación secundaria obligatoria. d) Los laboratorios para el bachillerato de la modalidad de ciencias y tecnología cubren la exigencia del laboratorio de ciencias experimentales para la educación secundaria obligatoria. Del mismo modo, el aula de tecnología para el bachillerato cubre la exigencia del aula taller de tecnologías para la educación secundaria obligatoria. 4. Disposición adicional primera. Centros que ofrecen la educación de personas adultas. 1. 2. Los requisitos de instalaciones se adecuarán a la organización específica de las enseñanzas de adultos. Disposición adicional segunda. Centros de educación especial. Disposición adicional tercera. Centros que atiendan a poblaciones de especiales características sociodemográficas. 1. 2. 3. cv e: B O E -A -2 01 0- 41 32 BOLETÍN OFICIAL DEL ESTADO Núm. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 24839 Disposición adicional cuarta. Centros docentes reconocidos por acuerdos internacionales. Los requisitos de los centros docentes cuyo carácter específico esté reconocido por acuerdos internacionales de carácter bilateral podrán ser adaptados por el Ministerio de Educación. Disposición adicional quinta. Centros acogidos al régimen de conciertos. Disposición adicional sexta. Inscripción en Registro. Disposición adicional séptima. Centros sometidos al Derecho común. Disposición adicional octava. Profesionales habilitados. 1. 2. Disposición adicional novena. Referencias genéricas. Todas las referencias para las que en este real decreto se utiliza la forma de masculino genérico, deben entenderse aplicables, indistintamente, a mujeres y a hombres. Disposición transitoria primera. Solicitudes de autorización de nuevos centros. 1. 2. 3. 62 Viernes 12 de marzo de 2010 Sec. I. Pág. 24840 mismo, se regirán, en lo relacionado a las instalaciones, a la normativa en vigor en el momento de realizar dicha aprobación. Disposición transitoria segunda. Acreditación de la habilitación para la docencia. Disposición transitoria tercera. Disposición derogatoria única. Derogación normativa. 1. 2. Quedan derogadas cuantas disposiciones de igual o inferior rango se opongan a lo dispuesto en este real decreto. Disposición final primera. Título competencial. Disposición final segunda. Desarrollo normativo. Disposición final tercera. Entrada en vigor. El presente real decreto entrará en vigor el día siguiente al de su publicación en el «Boletín Oficial del Estado». Dado en Madrid, el 12 de febrero de 2010.\n"
     ]
    }
   ],
   "source": [
    "# resume_pdfs('prueba_es.pdf', 0.8)\n",
    "resume = resume_pdfs('BOE-A-2010-4132.pdf', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import textract\n",
    "# PDF_read = textract.process('BOE-A-2010-4132.pdf', method='pdfminer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd380594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdfminer.high_level import extract_text\n",
    "# PDF_read = extract_text('prueba_es.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file\n",
    "# Para instalar java runtime en anaconda: https://anaconda.org/cyclus/java-jre\n",
    "from tika import parser\n",
    "\n",
    "raw = parser.from_file('prueba_es.pdf')\n",
    "print(raw['content'])\n",
    "\n",
    "texto_2 = \" \".join(raw['content'].split())\n",
    "texto_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b285d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ddedc7d",
   "metadata": {},
   "source": [
    "# Pruebas para otro proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9542ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'tes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8\n",
    "# https://stackoverflow.com/questions/56955320/file-contain-u00c2-u00a0-convert-to-characters\n",
    "\n",
    "import json\n",
    "# load data using Python JSON module\n",
    "with open('jsonformatter.json','r', encoding=['Latin1']) as f:\n",
    "    data = json.loads(f.read())\n",
    "# Flatten data\n",
    "data_json = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b451f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/56955320/file-contain-u00c2-u00a0-convert-to-characters\n",
    "# https://jsonformatter.org/json-parser\n",
    "with open(\"jsonformatter.json\", encoding='utf8') as f:\n",
    "    data = json.loads(f.read().encode('Latin1').decode('utf8'))\n",
    "    print(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json_formatted_1 = data_json.to_json(orient=\"split\")\n",
    "data_json_formatted_2 = data_json.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data_json_formatted.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(data_json_formatted, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('data_json_formatted_split.json', 'w') as f:\n",
    "    f.write(data_json_formatted_1)\n",
    "0\n",
    "with open('data_json_formatted_records.json', 'w') as f:\n",
    "    f.write(data_json_formatted_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json_formatted_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6b381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
